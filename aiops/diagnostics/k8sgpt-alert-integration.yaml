apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-k8sgpt-integration
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'default'
      routes:
        # Critical alerts trigger K8sGPT analysis
        - match:
            severity: critical
          receiver: 'k8sgpt-analyzer'
          continue: true
        - match:
            alertname: KarpenterNodeProvisioningFailed
          receiver: 'k8sgpt-analyzer'
        - match:
            alertname: PodCrashLoopBackOff
          receiver: 'k8sgpt-analyzer'
        - match:
            alertname: HighCPUUsage
          receiver: 'k8sgpt-analyzer'
    
    receivers:
      - name: 'default'
        webhook_configs:
          - url: 'http://k8sgpt-operator.k8sgpt.svc.cluster.local:8080/api/v1/webhook'
            send_resolved: false
      
      - name: 'k8sgpt-analyzer'
        webhook_configs:
          - url: 'http://k8sgpt-operator.k8sgpt.svc.cluster.local:8080/api/v1/analyze/alert'
            http_config:
              bearer_token_file: /var/run/secrets/k8sgpt/token
            send_resolved: false
---
# K8sGPT Alert Handler Service
apiVersion: v1
kind: Service
metadata:
  name: k8sgpt-webhook
  namespace: k8sgpt
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: 8080
      name: http
  selector:
    app: k8sgpt-operator
---
# Example: Auto-triggered K8sGPT analysis on alert
apiVersion: batch/v1
kind: CronJob
metadata:
  name: k8sgpt-periodic-analysis
  namespace: k8sgpt
spec:
  schedule: "*/30 * * * *"  # Every 30 minutes
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: k8sgpt-operator
          containers:
            - name: k8sgpt-analyzer
              image: k8sgpt/k8sgpt:latest
              command:
                - k8sgpt
                - analyze
                - --namespace
                - default
                - --output
                - json
                - --filter
                - Pod,Deployment,Node,KarpenterNodePool
              env:
                - name: K8SGPT_PROVIDER
                  value: "openai"
                - name: K8SGPT_MODEL
                  value: "gpt-4o-mini"
                - name: OPENAI_API_KEY
                  valueFrom:
                    secretKeyRef:
                      name: k8sgpt-secrets
                      key: openai-api-key
              resources:
                requests:
                  cpu: 100m
                  memory: 256Mi
                limits:
                  cpu: 500m
                  memory: 512Mi

